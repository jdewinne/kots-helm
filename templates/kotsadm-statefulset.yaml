{{ if not .Values.withMinio }}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    {{- include "admin-console.labels" . | nindent 4 }}
  name: kotsadm
spec:
  selector:
    matchLabels:
      app: kotsadm
  serviceName: kotsadm
  template:
    metadata:
      annotations:
        backup.velero.io/backup-volumes: backup
        pre.hook.backup.velero.io/command: '["/backup.sh"]'
        pre.hook.backup.velero.io/timeout: 10m
      labels:
        app: kotsadm
        {{- include "admin-console.labels" . | nindent 8 }}
    spec:
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      containers:
      - env:
        - name: SHARED_PASSWORD_BCRYPT
          valueFrom:
            secretKeyRef:
              key: passwordBcrypt
              name: kotsadm-password
        - name: AUTO_CREATE_CLUSTER_TOKEN
          valueFrom:
            secretKeyRef:
              key: kotsadm-cluster-token
              name: kotsadm-cluster-token
        - name: SESSION_KEY
          valueFrom:
            secretKeyRef:
              key: key
              name: kotsadm-session
{{ if not .Values.isHelmManaged }}
        - name: RQLITE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: kotsadm-rqlite
        - name: RQLITE_URI
          valueFrom:
            secretKeyRef:
              key: uri
              name: kotsadm-rqlite
{{ end }}
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_OWNER_KIND
          value: deployment
        - name: API_ENCRYPTION_KEY
          valueFrom:
            secretKeyRef:
              key: encryptionKey
              name: kotsadm-encryption
        - name: API_ENDPOINT
          value: http://kotsadm.{{ .Release.Namespace }}.svc.cluster.local:3000
        - name: API_ADVERTISE_ENDPOINT
          value: http://localhost:8800
{{ if .Values.embeddedClusterID }}
        - name: EMBEDDED_CLUSTER_ID
          value: {{ .Values.embeddedClusterID | quote }}
{{ end }}
{{ if .Values.embeddedClusterVersion }}
        - name: EMBEDDED_CLUSTER_VERSION
          value: {{ .Values.embeddedClusterVersion | quote }}
{{ end }}
        - name: HTTP_PROXY
        - name: HTTPS_PROXY
        - name: NO_PROXY
          value: kotsadm-rqlite,kotsadm-api-node
        - name: IS_HELM_MANAGED
          value: {{ .Values.isHelmManaged | quote }}
        image: {{ .Values.images.kotsadm }}
        imagePullPolicy: IfNotPresent
        name: kotsadm
        ports:
        - containerPort: 3000
          name: http
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 3000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
        resources:
          limits:
            cpu: "1"
            memory: 2Gi
          requests:
            cpu: 100m
            memory: 100Mi
        volumeMounts:
        - mountPath: /kotsadmdata
          name: kotsadmdata
        - mountPath: /backup
          name: backup
        - mountPath: /tmp
          name: tmp
{{ if not .Values.isHelmManaged }}
      initContainers:
      - args:
        - plan
        env:
        - name: SCHEMAHERO_DRIVER
          value: rqlite
        - name: SCHEMAHERO_SPEC_FILE
          value: /tables
        - name: SCHEMAHERO_OUT
          value: /migrations/plan.yaml
        - name: SCHEMAHERO_URI
          valueFrom:
            secretKeyRef:
              key: uri
              name: kotsadm-rqlite
        image: {{ .Values.images.migrations }}
        imagePullPolicy: IfNotPresent
        name: schemahero-plan
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
          requests:
            cpu: 50m
            memory: 50Mi
        volumeMounts:
        - mountPath: /migrations
          name: migrations
      - args:
        - apply
        env:
        - name: SCHEMAHERO_DRIVER
          value: rqlite
        - name: SCHEMAHERO_DDL
          value: /migrations/plan.yaml
        - name: SCHEMAHERO_URI
          valueFrom:
            secretKeyRef:
              key: uri
              name: kotsadm-rqlite
        image: {{ .Values.images.migrations }}
        imagePullPolicy: IfNotPresent
        name: schemahero-apply
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
          requests:
            cpu: 50m
            memory: 50Mi
        volumeMounts:
        - mountPath: /migrations
          name: migrations
      - command:
        - /restore.sh
        env:
        - name: RQLITE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: kotsadm-rqlite
        image: {{ .Values.images.kotsadm }}
        imagePullPolicy: IfNotPresent
        name: restore-data
        resources:
          limits:
            cpu: "1"
            memory: 2Gi
          requests:
            cpu: 100m
            memory: 100Mi
        volumeMounts:
        - mountPath: /kotsadmdata
          name: kotsadmdata
        - mountPath: /backup
          name: backup
        - mountPath: /tmp
          name: tmp
{{ end }}
      restartPolicy: Always
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      serviceAccountName: kotsadm
      volumes:
      - persistentVolumeClaim:
          claimName: kotsadmdata
        name: kotsadmdata
      - emptyDir:
          medium: Memory
        name: migrations
      - emptyDir: {}
        name: backup
      - emptyDir: {}
        name: tmp
{{ $kotsminio := lookup "apps/v1" "StatefulSet" .Release.Namespace "kotsadm-minio" }}
{{ if not $kotsminio }}
{{ $existingpvc := lookup "v1" "PersistentVolumeClaim" .Release.Namespace "kotsadmdata" }}
{{ if not $existingpvc }}
# if the migration occurred, the pvc will already exist
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kotsadmdata
  labels:
    {{- include "admin-console.immutableLabels" . | nindent 4 }}
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 4Gi
{{ end }}
{{ else }}
# if minio exists, we need to migrate the data to a pvc
---
apiVersion: batch/v1
kind: Job
metadata:
  name: kotsadm-migrate-s3
  annotations:
    helm.sh/hook: pre-upgrade
    helm.sh/hook-weight: "1"
  labels:
    {{- include "admin-console.labels" . | nindent 4 }}
spec:
  template:
    metadata:
      labels:
        {{- include "admin-console.labels" . | nindent 8 }}
    spec:
      initContainers:
      - command:
        - /bin/sh
        - -c
        - |
          kubectl scale deploy/kotsadm -n {{ .Release.Namespace }} --replicas=0
          kubectl wait --for delete pod --selector=app=kotsadm -n {{ .Release.Namespace }} --timeout=300s
        image: {{ .Values.images.kotsadm }}
        imagePullPolicy: IfNotPresent
        name: scale-down-kotsadm
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
      containers:
      - command:
        - /migrate-s3.sh
        env:
        - name: S3_ENDPOINT
          value: http://kotsadm-minio:9000
        - name: S3_BUCKET_NAME
          value: kotsadm
        - name: S3_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              key: accesskey
              name: kotsadm-minio
        - name: S3_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              key: secretkey
              name: kotsadm-minio
        - name: S3_BUCKET_ENDPOINT
          value: "true"
        image: {{ .Values.images.kotsadm }}
        imagePullPolicy: IfNotPresent
        name: migrate-s3
        resources:
          limits:
            cpu: "1"
            memory: 2Gi
          requests:
            cpu: 100m
            memory: 100Mi
        volumeMounts:
        - mountPath: /kotsadmdata
          name: kotsadmdata
      restartPolicy: OnFailure
      serviceAccountName: kotsadm
      volumes:
      - persistentVolumeClaim:
          claimName: kotsadmdata
        name: kotsadmdata
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kotsadmdata
  annotations:
    helm.sh/hook: pre-upgrade
    helm.sh/hook-weight: "0"
  labels:
    {{- include "admin-console.immutableLabels" . | nindent 4 }}
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 4Gi
{{ end }}
{{ end }}

